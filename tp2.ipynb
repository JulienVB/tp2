{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP2 - Julien Vanbelle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yake\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from IPython.display import Image\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import spacy\n",
    "from spacy.lang.fr.examples import sentences\n",
    "from textblob import Blobber\n",
    "from textblob_fr import PatternTagger, PatternAnalyzer\n",
    "from tabulate import tabulate\n",
    "\n",
    "year = 1890"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Création d'une liste de mots à ignorer\n",
    "ignored = set([\"conseil communal\", \"conseil général\", \"conseil d'administration\",\"conseil supérieur\",\"conseil provincial\"])\n",
    "ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantier l'extracteur de mots clés\n",
    "kw_extractor = yake.KeywordExtractor(lan=\"fr\", top=50)\n",
    "kw_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lister les Fichiers\n",
    "data_path = \"/Users/julienvanbelle/Documents/GitHub/tac/data/txt\"\n",
    "files = os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimer le nombre de fichiers identifiés\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enlever les fichiers qui ne commencent pas par Bxl_\n",
    "date_files = [f for f in files if f.startswith('Bxl_1890')]\n",
    "len(date_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in sorted(date_files):\n",
    "    text = open(os.path.join(data_path, f), 'r').read()\n",
    "    keywords = kw_extractor.extract_keywords(text.lower())  ##.lower() ==> permet de mettre le texte en miniscule\n",
    "    kept = []\n",
    "    for kw, score in keywords:\n",
    "        words = kw.split()\n",
    "        if len(words) == 2 and kw.lower() not in ignored:\n",
    "            kept.append(kw)\n",
    "    print(f\"{f} mentions these keywords: {', '.join(kept)}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords (Idem que dans s1)\n",
    "sw = stopwords.words(\"french\")\n",
    "sw += [\"les\", \"plus\", \"cette\", \"fait\", \"faire\", \"être\", \"deux\", \"comme\", \"dont\", \"tout\",\n",
    "       \"ils\", \"bien\", \"sans\", \"peut\", \"tous\", \"après\", \"ainsi\", \"donc\", \"cet\", \"sous\",\n",
    "       \"celle\", \"entre\", \"encore\", \"toutes\", \"pendant\", \"moins\", \"dire\", \"cela\", \"non\",\n",
    "       \"faut\", \"trois\", \"aussi\", \"dit\", \"avoir\", \"doit\", \"contre\", \"depuis\", \"autres\",\n",
    "       \"van\", \"het\", \"autre\", \"jusqu\", \"ville\"]\n",
    "sw = set(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stocker le contenu de ces fichiers dans une liste\n",
    "content_list = []\n",
    "for txt in date_files:\n",
    "    with open(os.path.join(data_path, txt), 'r') as f:\n",
    "        content_list.append(f.read())\n",
    "\n",
    "len(content_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ecrire tout le contenu dans un fichier temporaire\n",
    "temp_path = '/Users/julienvanbelle/Documents/GitHub/tac/data'\n",
    "if not os.path.exists(temp_path):\n",
    "    os.mkdir(temp_path)\n",
    "with open(os.path.join(temp_path, f'{year}.txt'), 'w') as f:\n",
    "    f.write(' '.join(content_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimer le contenu du fichier et constater les \"déchets\"\n",
    "with open(os.path.join(temp_path, f'{year}.txt'), 'r') as f:\n",
    "    before = f.read()\n",
    "\n",
    "before[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(year, folder=None):\n",
    "    if folder is None:\n",
    "        input_path = f\"{year}.txt\"\n",
    "        output_path = f\"{year}_clean.txt\"\n",
    "    else:\n",
    "        input_path = f\"{folder}/{year}.txt\"\n",
    "        output_path = f\"{folder}/{year}_clean.txt\"\n",
    "    output = open(output_path, \"w\", encoding='utf-8')\n",
    "    with open(input_path, encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        words = nltk.wordpunct_tokenize(text)\n",
    "        kept = [w.lower() for w in words if len(w) > 2 and w.isalpha() and w.lower() not in sw]\n",
    "        kept_string = \" \".join(kept)\n",
    "        output.write(kept_string)\n",
    "    return f'Output has been written in {output_path}!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text(year, folder=temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier le résultat\n",
    "with open(os.path.join(temp_path, f'{year}_clean.txt'), 'r') as f:\n",
    "    after = f.read()\n",
    "\n",
    "after[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = Counter(after.split())\n",
    "print(frequencies.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = WordCloud(width=2000, height=1000, background_color='white').generate_from_frequencies(frequencies)\n",
    "cloud.to_file(os.path.join(temp_path, f\"{year}.png\"))\n",
    "Image(filename=os.path.join(temp_path, f\"{year}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('fr_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le texte\n",
    "n=900000\n",
    "text = open(\"/Users/julienvanbelle/Documents/GitHub/tac/data/all.txt\", encoding='utf-8').read()[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Traiter le texte\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compter les entités\n",
    "people = defaultdict(int)\n",
    "organisation = defaultdict(int)\n",
    "places = defaultdict(int)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"PER\" and len(ent.text) > 3:\n",
    "        people[ent.text] += 1\n",
    "    if ent.label_ == \"ORG\" and len(ent.text) > 3:\n",
    "        organisation[ent.text] += 1\n",
    "    if ent.label_ == \"LOC\" and len(ent.text) > 3:\n",
    "        places[ent.text] += 1\n",
    "      \n",
    "    \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trier et imprimer\n",
    "\n",
    "sorted_people = sorted(people.items(), key=lambda kv: kv[1], reverse=True)\n",
    "sorted_organisation = sorted(organisation.items(), key=lambda kv: kv[1], reverse=True)\n",
    "sorted_places = sorted(places.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "\n",
    "for person, freq in sorted_people:\n",
    "    print(f\"{person} (PER)apparait {freq} fois dans le corpus\")\n",
    "\n",
    "for organisation, freq in sorted_organisation:\n",
    "    print(f\"{organisation} (ORG)apparait {freq} fois dans le corpus\")\n",
    "\n",
    "for places, freq in sorted_places:\n",
    "    print(f\"{places} (LOC)apparait {freq} fois dans le corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_list = []\n",
    "\n",
    "phrase1 = \"C'est dire que vous avez des facultés et des aptitudes spéciales pour l'art auquel vous avez consacré votre vie.\"\n",
    "phrase2 = \"Les artistes musiciens et choristes du théâtre de l'Alhambra sollicitent un subside à l'effet de pouvoir organiser des concerts classiques et hebdomadaires.\"\n",
    "phrase3 = \"M. Yseux. J'ai posé la question de savoir si le fait est vrai ou faux.\"\n",
    "phrase4 = \"Dans ces conditions, nous espérons que la Députation permanente refusera de mandater d'office une dépense qui légalement nenous incombe pas. Au besoin, la justice sera appelée à statuer.\"\n",
    "phrase5 = \"Le directeur fait, à la fin de chaque mois, le dépouillement des certificats délivrés par les chefs de service aux internes et aux externes et le transmet au Secrétariat général.\"\n",
    "phrase6 = \"Il prépare les médicaments nécessaires et surveille l'administration de ceux-ci ; il ne peut modifier en rien les traitements indiqués par le médecin directeur, ni en instituer aucun autre, lorsque celui-ci est à l'hospice.\"\n",
    "phrase7 = \"Dans la dernière séance, nous avons voté poulies fêtes un crédit supplémentaire de 53,000 francs.\"\n",
    "phrase8 = \"Il était néanmoins difficile de la combler parce que, d'une part, les crédits votés par le Conseil communal devaient subvenir à de multiples emplois, et que, d'autre part, le crédit voté par les Chambres était des plus réduits.\"\n",
    "phrase9 = \"Nous ne pouvons mieux faire c o n n a î t r e la situation p r o s p è r e de l'Académie qu'en mentionnant le nombre d'élèves q u i ont é t é inscrits pour les cours d u soir, soit 7 5 9 , ce q u i , avec les 259 jeunes gens inscrits pour les cours du j o u r , forme un total de 1,018 élèves ; beaucoup d'entre eux se sont fait inscrire à la fois pour les cours du jour et du soir.\"\n",
    "phrase10 = \"Grâce à la généreuse intervention du fonds Bischoffsheim, l'ouverture de l'école a eu lieu le 9 septembre 1889.\"\n",
    "phrase_list.append(phrase1)\n",
    "phrase_list.append(phrase2)\n",
    "phrase_list.append(phrase3)\n",
    "phrase_list.append(phrase4)\n",
    "phrase_list.append(phrase5)\n",
    "phrase_list.append(phrase6)\n",
    "phrase_list.append(phrase7)\n",
    "phrase_list.append(phrase8)\n",
    "phrase_list.append(phrase9)\n",
    "phrase_list.append(phrase10)\n",
    "\n",
    "##print(phrase_list[:10])\n",
    "print(\"nb d'éléments dans la liste =\",len(phrase_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = Blobber(pos_tagger=PatternTagger(), analyzer=PatternAnalyzer())\n",
    "score_list = [['Polarity', 'Subjectivity']]\n",
    "def get_sentiment(input_text):\n",
    "    blob = tb(input_text)\n",
    "    polarity, subjectivity = blob.sentiment\n",
    "    polarity_perc = f\"{100*abs(polarity):.0f}\"\n",
    "    subjectivity_perc = f\"{100*subjectivity:.0f}\"\n",
    "    if polarity > 0:\n",
    "        polarity_str = f\"{polarity_perc}% positive\"\n",
    "    elif polarity < 0:\n",
    "        polarity_str = f\"{polarity_perc}% negative\"\n",
    "    else:\n",
    "        polarity_str = \"neutral\"\n",
    "    if subjectivity > 0:\n",
    "        subjectivity_str = f\"{subjectivity}% subjective\"\n",
    "    else:\n",
    "        subjectivity_str = \"perfectly objective\"\n",
    "    print(f\"This text is {polarity_str} and {subjectivity_str}.\")\n",
    "    score_list.append([polarity_str,subjectivity_str])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for y in range(0,len(phrase_list)):\n",
    " print(\"Phrase\", y+1, \"==\" ,phrase_list[y])\n",
    " get_sentiment(phrase_list[y])\n",
    " print()\n",
    " print(score_list[y+1])\n",
    " print()\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tabulate(score_list,headers='firstrow',tablefmt='fancy_grid'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
